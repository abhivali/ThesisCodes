{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f10732",
   "metadata": {},
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef13ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edempy import Deck\n",
    "from pyfedic.mesh import Mesh, gen_mesh\n",
    "from pyfedic.cells import T4\n",
    "import numpy as np\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f979b279",
   "metadata": {},
   "source": [
    "Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9865c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # \"Optional : to see some debug stuff\"\n",
    "    import logging\n",
    "    from logging import FileHandler\n",
    "    from pyfedic.tictoc import TICTOC\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(levelname)s :: %(message)s\"\n",
    "    )\n",
    "    logging.getLogger().setLevel(TICTOC)\n",
    "    \n",
    "\n",
    "# Function to extract required data from EDEM file\n",
    "def dataT(deck,t):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    deck : deck\n",
    "    t : Timestep\n",
    "    Returns\n",
    "    -------\n",
    "    dataS : [ids , Xpos, Ypos, Zpos, Radius, Quaternions(w,x,y,z)]\n",
    "    \"\"\"\n",
    "    print(f\"________Preparing data for the time step {t} ________\")\n",
    "    pids = []\n",
    "    ppos = []\n",
    "    p_radUS = []\n",
    "    QuaternionsUS = []\n",
    "    \n",
    "    for i in range(deck.timestep[t].numTypes):\n",
    "        #condition to check if particles of this type are created\n",
    "        if deck.timestep[t].particle[i].getNumParticles() > 0: \n",
    "            p = deck.timestep[t].particle[i].getIds()\n",
    "            pos = deck.timestep[t].particle[i].getPositions()\n",
    "            rad = deck.timestep[t].particle[i].getSphereRadii()\n",
    "            quaternions = deck.timestep[t].particle[i].getOrientation() # euler axis of rotation of particles\n",
    "            \n",
    "            pids.extend(p)\n",
    "            ppos.extend(pos)\n",
    "            p_radUS.extend(rad)\n",
    "            QuaternionsUS.extend(quaternions)\n",
    "\n",
    "    pids = np.array(pids)\n",
    "    ppos = np.array(ppos)\n",
    "    p_radUS = np.array(p_radUS)\n",
    "    QuaternionsUS = np.array(QuaternionsUS)\n",
    "    \n",
    "    dataUS = np.column_stack((pids,ppos,p_radUS,QuaternionsUS)) #combined data in the array format and is unsorted\n",
    "    dataS = dataUS[dataUS[:,0].argsort()] # Sorted data\n",
    "    \n",
    "    return dataS\n",
    "\n",
    "\n",
    "# Function for correcting displacements along the periodic boundaries\n",
    "def DispAlongPeriodicBounds(data_i, data_f, X_bounds = [-25.5,25.5], Y_bounds = [-25.5,25.5]):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_i : Array [X Y Z]\n",
    "    data_f : Array [X Y Z]\n",
    "    for the initial and final arrays the X and Y data should be in the 2nd and 3rd columns\n",
    "\n",
    "    X_bounds : list [X_min, X_max], optional\n",
    "        The default is [-25.5,25.5].\n",
    "    Y_bounds : list [Y_min, Y_max], optional\n",
    "        The default is [-25.5,25.5].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Displacements : [ Ux Uy Uz ]\n",
    "\n",
    "    \"\"\"\n",
    "    Xbl, = np.diff(X_bounds)\n",
    "    Ybl, = np.diff(Y_bounds)\n",
    "\n",
    "    Ux, Uy, Uz = (data_f - data_i).T\n",
    "\n",
    "    out = Ux > Xbl/2\n",
    "    Ux[out] -= Xbl\n",
    "    out = Ux < -Xbl/2\n",
    "    Ux[out] += Xbl\n",
    "\n",
    "    out = Uy > Ybl/2\n",
    "    Uy[out] -= Ybl\n",
    "    out = Uy < -Ybl/2\n",
    "    Uy[out] += Ybl\n",
    "\n",
    "    return np.vstack((Ux, Uy, Uz)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9cc1fc",
   "metadata": {},
   "source": [
    "File opening and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e66e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = r\"FileName.dem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02754be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for performing Homogenization\n",
    "\n",
    "# include rotations for the calculations\n",
    "Include_Rotations = True\n",
    "#Save particle density data\n",
    "ParticleDensityOutput = False\n",
    "# perform for onlu one timestep:\n",
    "one_Time = True\n",
    "\n",
    "# Size of element for meshing and homogenization\n",
    "Element_size = 2\n",
    "\n",
    "# 50x50\n",
    "# X_mesh = [-20, 20]\n",
    "# Y_mesh = [-20, 20]\n",
    "\n",
    "# 100x100\n",
    "# X_mesh = [-40, 40]\n",
    "# Y_mesh = [-40, 40]\n",
    "\n",
    "# 200x200\n",
    "X_mesh = [-90, 90]\n",
    "Y_mesh = [-90, 90]\n",
    "\n",
    "Z_mesh = [-38, 42]\n",
    "# Z_mesh = [-37, 38]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41392f71",
   "metadata": {},
   "source": [
    "Check if the file is already saved and open if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81567c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract deck from EDEM file\n",
    "\n",
    "file_path = Path(file_name)\n",
    "pickle_Save = file_path.parent\n",
    "pickleFileName = file_path.parts[-1][0:-4] +'.pickle'\n",
    "\n",
    "try:\n",
    "    saveDeck = False\n",
    "    with open( pickle_Save / pickleFileName , 'rb') as file:\n",
    "        deck = pickle.load(file)\n",
    "    print(\"________Pickle file available\")\n",
    "    \n",
    "    #  check if the file is in proper location\n",
    "    if(deck.__dict__['deckname'] != file_name):\n",
    "        print('Old pickle file needs update')\n",
    "        saveDeck = True\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"________Pickle file not found\")\n",
    "    saveDeck = True\n",
    "\n",
    "if saveDeck == True:\n",
    "    print(\"________Extracting deck\")\n",
    "    deck = Deck(file_name) # opening the deck\n",
    "    print(\"________Extracting deck : done\")\n",
    "    print(\"________Creating a Pickle file\")\n",
    "\n",
    "    with open( pickle_Save / pickleFileName, 'wb') as file:\n",
    "        pickle.dump(deck, file) # saving as pickle file as it is easier to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722421bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time start End and step size\n",
    "t_b = 5 #corresponds to timestep 3500\n",
    "t_final = len(deck.timestepKeys)-1\n",
    "step_size = 20\n",
    "\n",
    "# Periodic boundary limits\n",
    "X_Lims = [deck.timestep[0].domainMin[0] , deck.timestep[0].domainMax[0]]\n",
    "Y_Lims = [deck.timestep[0].domainMin[1] , deck.timestep[0].domainMax[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f5bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish the saving folder\n",
    "save_folder = Path(file_name).parent\n",
    "Sub_folder = 'Output_Strain_IncludingRotation_E' + str(Element_size)\n",
    "(save_folder / Sub_folder).mkdir(parents=True, exist_ok=True)\n",
    "(save_folder / Sub_folder / 'Results_Delaunay').mkdir(parents=True, exist_ok=True)\n",
    "(save_folder / Sub_folder / 'Results_interpolated_grid').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Timesteps required\n",
    "t_steps = np.arange(t_b+5,t_final,step_size).tolist()\n",
    "if (t_steps[-1] != t_final): t_steps.append(t_final)\n",
    "t_steps.insert(0,t_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74984e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Include_Rotations == True:\n",
    "    \n",
    "    (save_folder / Sub_folder / 'ResultsWithRotation').mkdir(parents=True, exist_ok=True)\n",
    "    (save_folder / Sub_folder / 'ResultsWithRotation' / 'Results_Delaunay').mkdir(parents=True, exist_ok=True)\n",
    "    (save_folder / Sub_folder / 'ResultsWithRotation' / 'Results_interpolated_grid').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    data0 = dataT(deck, t_b) # [ids , Xpos, Ypos, Zpos, Radius, Quaternions(w,x,y,z)]\n",
    "    Quaternions0 = data0[:,5::]\n",
    "           \n",
    "    # initial vector representing the orientation of the moment of inertia axis\n",
    "    # intersecting two points on the sphere at [0,0,1] and [0,0,-1]\n",
    "    Num_nodes = len(data0)*2 # two points for each particle\n",
    "    Unit_Moi_Vec = np.zeros((Num_nodes, 3))\n",
    "    Unit_Moi_Vec[0::2] = 1\n",
    "    Unit_Moi_Vec[1::2] = -1\n",
    "    \n",
    "    Node_Quats = np.zeros((Num_nodes, 4))\n",
    "    Node_Quats[0::2] = Quaternions0\n",
    "    Node_Quats[1::2] = Quaternions0\n",
    "    \n",
    "    Rotated_unit_Vec = R.from_quat(Node_Quats).apply(Unit_Moi_Vec)\n",
    "    \n",
    "    nodes0 = np.zeros((Num_nodes, 3))\n",
    "    nodes0[0::2] = data0[:,1:4] + data0[:,4].reshape(-1,1) * Rotated_unit_Vec[0::2]\n",
    "    nodes0[1::2] = data0[:,1:4] + data0[:,4].reshape(-1,1) * Rotated_unit_Vec[1::2]\n",
    "    \n",
    "    # Apply tessellation \n",
    "    cells = Delaunay(nodes0).simplices\n",
    "    m = Mesh.new(nodes0, {T4: cells})\n",
    "    nm = gen_mesh(\n",
    "        (X_mesh[0], X_mesh[1]),\n",
    "        (Y_mesh[0], Y_mesh[1]),\n",
    "        (Z_mesh[0], Z_mesh[1]),\n",
    "        elt_size = Element_size\n",
    "    )\n",
    "        \n",
    "    for i, t in enumerate(t_steps):\n",
    "        print('step', i)\n",
    "        \n",
    "        data = dataT(deck, t)\n",
    "        Quats = data[:,5::]\n",
    "              \n",
    "        Node_Quats = np.zeros((Num_nodes, 4))\n",
    "        Node_Quats[0::2] = Quats\n",
    "        Node_Quats[1::2] = Quats\n",
    "        \n",
    "        Rotated_unit_Vec = R.from_quat(Node_Quats).apply(Unit_Moi_Vec)\n",
    "        \n",
    "        nodes = np.zeros((Num_nodes, 3))\n",
    "        nodes[0::2] = data[:,1:4] + data[:,4].reshape(-1,1) * Rotated_unit_Vec[0::2]\n",
    "        nodes[1::2] = data[:,1:4] + data[:,4].reshape(-1,1) * Rotated_unit_Vec[1::2]\n",
    "\n",
    "        #correct the displacement across periodic boundaries\n",
    "        U = DispAlongPeriodicBounds(nodes0, nodes, X_bounds = [-25.5,25.5], Y_bounds = [-25.5,25.5])\n",
    "\n",
    "        # m.save(save_folder / Sub_folder / 'ResultsWithRotation'/ 'Results_Delaunay' / f'Result_{t:04d}.vtk', U, compute_eps=True)\n",
    "        nU = m.interp_V(U, nm, out=np.nan)\n",
    "        nU = nm.mean_V(nU, 2)\n",
    "        nm.save(save_folder / Sub_folder / 'ResultsWithRotation'/ 'Results_interpolated_grid' / f'Result_N{t:04d}.vtk', nU, compute_eps=True)\n",
    "        \n",
    "        Unit_Moi_Vec = np.copy(Rotated_unit_Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db44af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Triangulation for the initial timestep\n",
    "Data_B = dataT(deck, t_b)\n",
    "nodes = Data_B[:,1:4]\n",
    "cells = Delaunay(nodes).simplices\n",
    "m = Mesh.new(nodes, {T4: cells})\n",
    "nm = gen_mesh(\n",
    "    (X_mesh[0], X_mesh[1]),\n",
    "    (Y_mesh[0], Y_mesh[1]),\n",
    "    (Z_mesh[0], Z_mesh[1]),\n",
    "    elt_size = Element_size\n",
    ")\n",
    "\n",
    "for i, t in enumerate(t_steps):\n",
    "    print('step', i)\n",
    "    data = dataT(deck, t)[:,1:4]\n",
    "\n",
    "    #correct the displacement across periodic boundaries\n",
    "    U = DispAlongPeriodicBounds(nodes, data, X_bounds = [X_Lims[0], X_Lims[1]], Y_bounds = [Y_Lims[0],Y_Lims[0]])\n",
    "\n",
    "    # m.save(save_folder / Sub_folder / 'Results_Delaunay' / f'Result_{t:04d}.vtk', U, compute_eps=True)\n",
    "    nU = m.interp_V(U, nm, out=np.nan)\n",
    "    nU = nm.mean_V(nU, 2)\n",
    "    nm.save(save_folder / Sub_folder / 'Results_interpolated_grid' / f'Result_N{t:04d}.vtk', nU, compute_eps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ParticleDensityOutput == True:\n",
    "    from pyfedic.io import write_mesh\n",
    "    \n",
    "    # The value of density is normalised to -1 for graphite particles and +1 for silicon particles\n",
    "    density  = np.array([[1.99,-1],[2.8,-1],[3.6,-1],[4.8,-1],[6,-1],[6.5,-1],[7.5,-1],[0.61,1],[0.81,1],[1.02,1],[1.33,1],[1.63,1],[1.84,1],[2.04,1]])\n",
    "    \n",
    "    # Perform lookup based on the particle radii data\n",
    "    P_density = np.zeros(len(Data_B))\n",
    "    for i,j in enumerate(density[:,0]):\n",
    "        P_density[Data_B[:,4] == j] = density[i,1]\n",
    "    \n",
    "    # generate new mesh for density\n",
    "    m_d = Mesh.new(nodes, {T4: cells})\n",
    "    \n",
    "    nm_d = gen_mesh(\n",
    "            (X_mesh[0], X_mesh[1]),\n",
    "            (Y_mesh[0], Y_mesh[1]),\n",
    "            (Z_mesh[0], Z_mesh[1]),\n",
    "            zoi = Element_size\n",
    "            )\n",
    "    \n",
    "    write_mesh(save_folder / Sub_folder / 'Density.vtk', m_d, point_values = {'Density': P_density.flatten()})\n",
    "    \n",
    "    nP_density = m_d.interp_V(P_density, nm_d, out=np.nan)\n",
    "    nP_density = nm_d.mean_V(nP_density, 2)\n",
    "    \n",
    "    write_mesh(save_folder / Sub_folder / 'InterpolatedDensity.vtk', nm_d, point_values = {'Density': nP_density.flatten()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
